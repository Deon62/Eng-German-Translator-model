{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deon62/Eng-German-Translator-model/blob/main/translator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drchBN_mG30o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWMgHABfquaj"
      },
      "source": [
        "will be fine tuning a model to translate english words to german\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGW0ymdQG30v",
        "outputId": "c1303749-ba9e-4e5d-a0ed-d37e5e455e61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch: 2.8.0+cu126\n",
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "!pip install -q  sacrebleu\n",
        "import torch\n",
        "\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlGOFhmmG30z",
        "outputId": "8a5e8484-a612-4fa0-82ad-7a116015c9ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA Device Count: 1\n",
            "Current Device: 0\n",
            "Device Name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
        "print(\"Current Device:\", torch.cuda.current_device())\n",
        "print(\"Device Name:\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drdXrKA7G300"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRid4wVrG301",
        "outputId": "4c655922-6baa-4a76-f5f6-b724134173e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# we will now load our dataset, just 1% of it\n",
        "\n",
        "train_ds = load_dataset(\"wmt16\", \"de-en\", split=\"train[:1%]\")\n",
        "val_ds = load_dataset(\"wmt16\", \"de-en\", split=\"validation[:1%]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIjpPL5xG302"
      },
      "outputs": [],
      "source": [
        "# we will shuffle for randomness\n",
        "train_ds = train_ds.shuffle(seed=42)\n",
        "val_ds = val_ds.shuffle(seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gc2LINYtG303"
      },
      "outputs": [],
      "source": [
        "# Create train/validation split (90% train / 10% valid)\n",
        "spilt = train_ds.train_test_split(test_size=0.1, seed=42)\n",
        "train_raw = spilt[\"train\"]\n",
        "val_raw = spilt[\"test\"]\n",
        "test_raw = val_ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBTR430lG303",
        "outputId": "238f1bd3-4e0b-4d3a-d0cb-efdc733a73c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'translation': {'de': 'Ich würde zur Zulassung einer großen Zahl von Projekten raten, weil klar ist, daß die kulturellen Projekte sehr viele Investitionen Autonomer Gemeinschaften und privater Initiativen anziehen, die uns nicht verloren gehen dürfen.', 'en': 'I would recommend that many projects be allowed since it is clear that cultural projects attract a lot of investment from Autonomous Regions and private initiatives which we cannot afford to lose.'}}\n"
          ]
        }
      ],
      "source": [
        "print(train_raw[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-72kGrhDG304",
        "outputId": "7e9756c6-94b8-4cb1-ade1-75647b9b1041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN SAMPLES:\n",
            "EN: I would recommend that many projects be allowed since it is clear that cultural projects attract a lot of investment from Autonomous Regions and private initiatives which we cannot afford to lose.\n",
            "DE: Ich würde zur Zulassung einer großen Zahl von Projekten raten, weil klar ist, daß die kulturellen Projekte sehr viele Investitionen Autonomer Gemeinschaften und privater Initiativen anziehen, die uns nicht verloren gehen dürfen.\n",
            "---\n",
            "EN: We constantly find ourselves having to deal with this contradiction, particularly as regards the rights of the child, an area where there are cases in which more than one country is involved and in which the victims are not only not notified by the state where the judgement is made, but are also deprived of legal support.\n",
            "DE: Und mit diesem Widerspruch sehen wir uns vor allem in bezug auf die Rechte der Kinder permanent konfrontiert. In diesem Bereich gibt es Fälle, bei denen mehrere Länder beteiligt sind und die Opfer von dem Land, in dem das Gerichtsverfahren stattfindet, weder benachrichtigt werden noch Rechtsbeistand erhalten.\n",
            "---\n",
            "EN: In all social systems and at all periods in history, the most vulnerable groups have had the least purchasing power.\n",
            "DE: In allen gesellschaftlichen Systemen und Zeiten haben die schwächsten Gruppen auch die geringste Kaufkraft gehabt.\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "def show_examples(ds, n=3):\n",
        "    for i in range(n):\n",
        "        ex = ds[i][\"translation\"]\n",
        "        print(f\"EN: {ex['en']}\\nDE: {ex['de']}\\n---\")\n",
        "\n",
        "print(\"TRAIN SAMPLES:\")\n",
        "show_examples(train_raw)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-fd-u5mG306"
      },
      "outputs": [],
      "source": [
        "MODEL_CHECKPOINT = \"t5-small\"\n",
        "PREFIX = \"translate English to German: \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TsTfU6GG307"
      },
      "outputs": [],
      "source": [
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "MAX_LEN = 128  # max token length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-yY5ZExG307"
      },
      "outputs": [],
      "source": [
        "def preprocess_fn(batch):\n",
        "    # Extract English + German pairs\n",
        "    en_texts = [ex[\"en\"] for ex in batch[\"translation\"]]\n",
        "    de_texts = [ex[\"de\"] for ex in batch[\"translation\"]]\n",
        "\n",
        "    # Add prefix to English (T5 needs task info)\n",
        "    model_inputs = tokenizer([PREFIX + text for text in en_texts],\n",
        "                             max_length=MAX_LEN, truncation=True)\n",
        "\n",
        "    # Tokenize German target text\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(de_texts, max_length=MAX_LEN, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "948d7a7928104365b47397e083615235"
          ]
        },
        "id": "sb66delbG308",
        "outputId": "5b59f22f-2bf6-4e3e-9f1f-06b3bfbced33"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "948d7a7928104365b47397e083615235",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4549 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4006: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# applying preprocessing to train, valid and test\n",
        "train_ds = train_raw.map(preprocess_fn, batched=True, remove_columns= train_raw.column_names )\n",
        "val_ds = val_raw.map(preprocess_fn, batched=True, remove_columns= val_raw.column_names )\n",
        "test_ds = test_raw.map(preprocess_fn, batched=True, remove_columns= test_raw.column_names )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZJsFE5iG309",
        "outputId": "10d9dfbd-e48d-4873-f7e8-b09ce2339716"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [13959, 1566, 12, 2968, 10, 27, 133, 1568, 24, 186, 1195, 36, 2225, 437, 34, 19, 964, 24, 2779, 1195, 5521, 3, 9, 418, 13, 1729, 45, 2040, 3114, 1162, 6163, 7, 11, 1045, 6985, 84, 62, 1178, 5293, 12, 2615, 5, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1674, 6368, 881, 1811, 20766, 645, 3, 6403, 10436, 193, 6593, 35, 1080, 29, 6, 5603, 8330, 229, 6, 3, 26, 7118, 67, 3, 25739, 29, 16356, 1319, 2584, 26709, 35, 2040, 3114, 49, 23961, 35, 64, 1045, 52, 12043, 29, 46, 7376, 6, 67, 1149, 311, 20098, 7455, 12443, 5, 1]}\n"
          ]
        }
      ],
      "source": [
        "print(train_ds[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytgQg40uG30-",
        "outputId": "419199da-0853-4250-fe37-4ad762311b31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input IDs: [13959, 1566, 12, 2968, 10, 27, 133, 1568, 24, 186, 1195, 36, 2225, 437, 34, 19, 964, 24, 2779, 1195]\n",
            "Labels: [1674, 6368, 881, 1811, 20766, 645, 3, 6403, 10436, 193, 6593, 35, 1080, 29, 6, 5603, 8330, 229, 6, 3]\n",
            "Decoded Input: translate English to German: I would recommend that many projects be allowed since it is clear that cultural projects attract a lot of investment from Autonomous Regions and private initiatives which we cannot afford to lose.</s>\n",
            "Decoded Label: Ich würde zur Zulassung einer großen Zahl von Projekten raten, weil klar ist, daß die kulturellen Projekte sehr viele Investitionen Autonomer Gemeinschaften und privater Initiativen anziehen, die uns nicht verloren gehen dürfen.</s>\n"
          ]
        }
      ],
      "source": [
        "print(\"Input IDs:\", train_ds[0][\"input_ids\"][:20])\n",
        "print(\"Labels:\", train_ds[0][\"labels\"][:20])\n",
        "\n",
        "# Decoded to human readability\n",
        "print(\"Decoded Input:\", tokenizer.decode(train_ds[0][\"input_ids\"]))\n",
        "print(\"Decoded Label:\", tokenizer.decode([id for id in train_ds[0][\"labels\"] if id != -100]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnuM1rI0G30_"
      },
      "outputs": [],
      "source": [
        "# load model\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1WzZNWBG30_"
      },
      "outputs": [],
      "source": [
        "# load collector\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOz71G8eG31A"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "bleu = evaluate.load(\"sacrebleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXQ6e-DQG31A"
      },
      "outputs": [],
      "source": [
        "def postprocess_text(preds, labels):\n",
        "    preds = [p.strip() for p in preds]\n",
        "    labels = [[l.strip()] for l in labels]  # sacrebleu expects list of lists\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    preds, labels = eval_pred\n",
        "\n",
        "    # Replace -100 (ignore index) with pad_token_id before decoding\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "    # Decode\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Postprocess\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    # Compute BLEU\n",
        "    result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "    return {\"bleu\": result[\"score\"]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZlkrBL9G31B",
        "outputId": "50c35d89-ae84-4f7e-b0ad-61c20cf3c37c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KeysView({'input_ids': tensor([[13959,  1566,    12,  2968,    10,    27,   133,  1568,    24,   186,\n",
            "          1195,    36,  2225,   437,    34,    19,   964,    24,  2779,  1195,\n",
            "          5521,     3,     9,   418,    13,  1729,    45,  2040,  3114,  1162,\n",
            "          6163,     7,    11,  1045,  6985,    84,    62,  1178,  5293,    12,\n",
            "          2615,     5,     1,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [13959,  1566,    12,  2968,    10,   101,  4259,   253,  3242,   578,\n",
            "            12,  1154,    28,    48, 27252,     6,  1989,    38,  9544,     8,\n",
            "          2166,    13,     8,   861,     6,    46,   616,   213,   132,    33,\n",
            "          1488,    16,    84,    72,   145,    80,   684,    19,  1381,    11,\n",
            "            16,    84,     8,  8926,    33,    59,   163,    59,     3, 15195,\n",
            "            57,     8,   538,   213,     8, 22555,    19,   263,     6,    68,\n",
            "            33,    92,     3, 30182,    13,  1281,   380,     5,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[ 1674,  6368,   881,  1811, 20766,   645,     3,  6403, 10436,   193,\n",
            "          6593,    35,  1080,    29,     6,  5603,  8330,   229,     6,     3,\n",
            "            26,  7118,    67,     3, 25739,    29, 16356,  1319,  2584, 26709,\n",
            "            35,  2040,  3114,    49, 23961,    35,    64,  1045,    52, 12043,\n",
            "            29,    46,  7376,     6,    67,  1149,   311, 20098,  7455, 12443,\n",
            "             5,     1,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "          -100,  -100,  -100,  -100],\n",
            "        [ 2203,   181,   637,    51, 29667,  6052,   558,  1149,   426,  4022,\n",
            "            16,    36,  5131,   219,    67,  8092,    15,    74,  2758,  3574,\n",
            "         10447,  6849,  1378,     5,    86,   637,    51,  5728,  1505,     3,\n",
            "            15,     7, 31596,     6,   468,   177,    35,  7461, 24886, 25477,\n",
            "           436,    64,    67, 25209,   193,   340,  2216,     6,    16,   340,\n",
            "           211, 16419,     7, 16052,  6594,  8954,    15,    17,     6,     3,\n",
            "         26682,    36,  6359,  3723,  2880,    17,   404,   763, 11013,  5358,\n",
            "          2976,  4875,     5,     1]]), 'decoder_input_ids': tensor([[    0,  1674,  6368,   881,  1811, 20766,   645,     3,  6403, 10436,\n",
            "           193,  6593,    35,  1080,    29,     6,  5603,  8330,   229,     6,\n",
            "             3,    26,  7118,    67,     3, 25739,    29, 16356,  1319,  2584,\n",
            "         26709,    35,  2040,  3114,    49, 23961,    35,    64,  1045,    52,\n",
            "         12043,    29,    46,  7376,     6,    67,  1149,   311, 20098,  7455,\n",
            "         12443,     5,     1,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0],\n",
            "        [    0,  2203,   181,   637,    51, 29667,  6052,   558,  1149,   426,\n",
            "          4022,    16,    36,  5131,   219,    67,  8092,    15,    74,  2758,\n",
            "          3574, 10447,  6849,  1378,     5,    86,   637,    51,  5728,  1505,\n",
            "             3,    15,     7, 31596,     6,   468,   177,    35,  7461, 24886,\n",
            "         25477,   436,    64,    67, 25209,   193,   340,  2216,     6,    16,\n",
            "           340,   211, 16419,     7, 16052,  6594,  8954,    15,    17,     6,\n",
            "             3, 26682,    36,  6359,  3723,  2880,    17,   404,   763, 11013,\n",
            "          5358,  2976,  4875,     5]])})\n",
            "Input shape: torch.Size([2, 69])\n"
          ]
        }
      ],
      "source": [
        "# collator batch\n",
        "batch = data_collator([train_ds[i] for i in range(2)])\n",
        "print(batch.keys())\n",
        "print(\"Input shape:\", batch[\"input_ids\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOdx5cNPG31B",
        "outputId": "e82b21a1-a666-4167-98b5-c7b3d6b8f57b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'bleu': 0.0}\n"
          ]
        }
      ],
      "source": [
        "# Test compute_metrics function (dummy preds)\n",
        "sample_preds = tokenizer([\"Hallo Welt\"], return_tensors=\"np\", padding=True)[\"input_ids\"]\n",
        "sample_labels = tokenizer([\"Hallo Welt\"], return_tensors=\"np\", padding=True)[\"input_ids\"]\n",
        "\n",
        "print(compute_metrics((sample_preds, sample_labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHe5-N5sG31C"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 3\n",
        "LR = 5e-5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nxr9no0oG31D",
        "outputId": "0793aaa0-5dfd-4c60-d7a2-d100be03ba22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: transformers 4.55.4\n",
            "Uninstalling transformers-4.55.4:\n",
            "  Successfully uninstalled transformers-4.55.4\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.0)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Using cached transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
            "Downloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers, accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.10.0\n",
            "    Uninstalling accelerate-1.10.0:\n",
            "      Successfully uninstalled accelerate-1.10.0\n",
            "Successfully installed accelerate-1.10.1 transformers-4.55.4\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "771a2caeba2c45fa9cf34f8d21c34496",
              "pip_warning": {
                "packages": [
                  "accelerate",
                  "transformers"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip uninstall -y transformers\n",
        "!pip install -U transformers accelerate datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htMLAm4cG31D",
        "outputId": "17b09125-1786-496f-bf68-3607dcf459ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.55.4\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "print(transformers.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McX_fgwpG31E"
      },
      "outputs": [],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"t5-en-de-out\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=LR,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    predict_with_generate=True,\n",
        "    fp16=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jx3nu5UXG31E"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuJfoFJZG31F"
      },
      "outputs": [],
      "source": [
        "train_subset = train_ds.select(range(min(len(train_ds), 2000)))\n",
        "eval_subset = test_ds.select(range(min(len(test_ds), 200)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwoK8FzzG31F",
        "outputId": "478756a0-47cb-4c87-f140-56a9b3e8585e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-585051638.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        }
      ],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_subset,\n",
        "    eval_dataset=eval_subset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2khoyahAG31G",
        "outputId": "345ae467-3bd5-4d52-d723-80336e9e8023"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m625deon\u001b[0m (\u001b[33m625deon-egerton-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250827_094714-qwi9icx4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/625deon-egerton-university/huggingface/runs/qwi9icx4' target=\"_blank\">rich-river-1</a></strong> to <a href='https://wandb.ai/625deon-egerton-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/625deon-egerton-university/huggingface' target=\"_blank\">https://wandb.ai/625deon-egerton-university/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/625deon-egerton-university/huggingface/runs/qwi9icx4' target=\"_blank\">https://wandb.ai/625deon-egerton-university/huggingface/runs/qwi9icx4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [750/750 02:09, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.988821</td>\n",
              "      <td>19.596361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.289000</td>\n",
              "      <td>0.991289</td>\n",
              "      <td>19.489041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.289000</td>\n",
              "      <td>0.991105</td>\n",
              "      <td>19.489041</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=750, training_loss=1.2735617268880208, metrics={'train_runtime': 434.0097, 'train_samples_per_second': 13.825, 'train_steps_per_second': 1.728, 'total_flos': 110269732749312.0, 'train_loss': 1.2735617268880208, 'epoch': 3.0})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyQPx63qG31G",
        "outputId": "3c1985c4-761a-48e5-9cca-04e18b7c64e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['It is claimed Webster attacked her while she was \"unconscious, asleep and incapable of giving consent.\"', 'Karratha Police have charged a 20-year-old man with failing to stop and reckless driving.', \"He is alleged to have raped a woman at the Scotland's Hotel in Pitlochry in Perthshire on June 7, 2013.\", 'Congressmen Keith Ellison and John Lewis have proposed legislation to protect union organizing as a civil right.', 'The motorcycle was seized and impounded for three months.']\n"
          ]
        }
      ],
      "source": [
        "sample_texts = [ex[\"en\"] for ex in test_raw[\"translation\"][:5]]\n",
        "print(sample_texts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pd1DeqEGG31H",
        "outputId": "3e9e606f-7e8d-415b-b7a9-d5077ff64b1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EN: It is claimed Webster attacked her while she was \"unconscious, asleep and incapable of giving consent.\"\n",
            "DE: Es wird behauptet, Webster habe sie angegriffen, als sie \"unbewusst, schlafend und unfähig war, ihre Zustimmung zu geben\".\n",
            "----------------------------------------\n",
            "EN: Karratha Police have charged a 20-year-old man with failing to stop and reckless driving.\n",
            "DE: Die Polizei von Karratha hat einen 20-jährigen Mann angeklagt, er sei nicht daran gehindert und fahrlässig zu fahren.\n",
            "----------------------------------------\n",
            "EN: He is alleged to have raped a woman at the Scotland's Hotel in Pitlochry in Perthshire on June 7, 2013.\n",
            "DE: Er soll am 7. Juni 2013 eine Frau im Scottish's Hotel in Pitlochry in Perthshire vergewaltigt haben.\n",
            "----------------------------------------\n",
            "EN: Congressmen Keith Ellison and John Lewis have proposed legislation to protect union organizing as a civil right.\n",
            "DE: Die Kongressabgeordneten Keith Ellison und John Lewis haben Gesetze vorgeschlagen, um die Gewerkschaftsorganisation als Bürgerrecht zu schützen.\n",
            "----------------------------------------\n",
            "EN: The motorcycle was seized and impounded for three months.\n",
            "DE: Das Motorrad wurde drei Monate lang beschlagnahmt und begrenzt.\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Tokenize with prefix (important for T5)\n",
        "inputs = tokenizer([PREFIX + text for text in sample_texts],\n",
        "                   return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
        "\n",
        "# Generate translations\n",
        "outputs = model.generate(**inputs, max_length=MAX_LEN)\n",
        "\n",
        "# Decode\n",
        "translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "for en, de in zip(sample_texts, translations):\n",
        "    print(f\"EN: {en}\")\n",
        "    print(f\"DE: {de}\")\n",
        "    print(\"-\" * 40)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMkMk6T1G31I",
        "outputId": "4b9c6026-6162-4c2d-f74e-bf4b4b693f74"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "predictions = trainer.predict(eval_subset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_HQtnUMG31K",
        "outputId": "3f10c723-bd5c-49fc-a94e-314147a89399"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PredictionOutput(predictions=array([[    0,  1122,   551,    36, 16512,    15,    17,     6,  1620,\n",
            "         1370,  2010,   680,     3,  3280, 11442,    35,     6,   501,\n",
            "          680,    96,   202],\n",
            "       [    0,   316, 16483,   193,  4556,  1795,  1024,     3,   547,\n",
            "          595,   460,    18, 20025,  6362,     3,  3280,   157,  5430,\n",
            "           17,     6,     3],\n",
            "       [    0,   848,  3775,   183,  4306, 12170,  2038,   266,  7672,\n",
            "          256, 12580,    31,     7,  2282,    16, 13430, 23654,   651,\n",
            "           16, 22343,  5718],\n",
            "       [    0,   316,  2974, 10292,     9,   115, 19522,    35, 17017,\n",
            "        22342,   106,    64,  1079,  9765,   745,   961,  2244,   776,\n",
            "          426, 24883,     6],\n",
            "       [    0,   644,  5083,  5672,  1177,  4052, 17605, 12142,    36,\n",
            "         9444, 18069,    17,    64,    36, 28539,     5,     1,     0,\n",
            "            0,     0,     0],\n",
            "       [    0,  3080,  1620,  1370,     6,  2059,  3861,  4445,     6,\n",
            "            3,   547,   289,     3,  5729,   645,   389, 12782,   425,\n",
            "          426,   340,  1546],\n",
            "       [    0,   316, 16483,    16,  4556,  1795,  1024,     3,   547,\n",
            "         4270, 20147, 18246,     6,   236,     3, 16193,    15,     7,\n",
            "         5083,  5672,   170],\n",
            "       [    0,   890,  5083,  5672,  1177,    36,  9444, 18069,    17,\n",
            "            6,   559,  1778,     3,    15,     7,    16,   645,  2861,\n",
            "         2280,    87,   107],\n",
            "       [    0,   644,  5083,  5672,    64,   266,  5780,     6,    67,\n",
            "           74, 28509,    93, 23566,     7,     3,  3280, 14202,   229,\n",
            "            6,  3163,  1352],\n",
            "       [    0,  1662,    74, 12477, 10660,  5674,    67,     3, 31629,\n",
            "          218,   266, 28783,    15,   206,  9434,   355, 15671,     5,\n",
            "            1,     0,     0],\n",
            "       [    0,    86,   304,  2168,    32,     3, 10629,   289,    67,\n",
            "         6552, 17791, 10194,    35,     7,    64,  3411,     7,     1,\n",
            "            0,     0,     0],\n",
            "       [    0,  1620,  1370,   551,  1352,   183,  2853,  2636,  1412,\n",
            "            3,  6050,   781,   397,  5380,  2880,  1818,   645,     3,\n",
            "        12843,  7672,   256],\n",
            "       [    0,   316, 16483,    16,  4556,  1795,  1024,   548, 14786,\n",
            "           17,   460,    18, 15903,   559,    74,  7341, 28053,     7,\n",
            "           18,   329,    32],\n",
            "       [    0,   848,  3775,   183,  1902,     5,  1600,   256, 22673,\n",
            "         3109,    17, 13030,  4556,  1795,  1024, 26354,     5,     1,\n",
            "            0,     0,     0],\n",
            "       [    0,   890,  6362,   551,   426, 16419,     3,  5371,     6,\n",
            "           74,  8608,    16,  2352, 13300,   548,   397,  5380,  2880,\n",
            "           17,     3,   547],\n",
            "       [    0,   316, 15158,   760,  5226,    93,     3, 23384,    29,\n",
            "        13079,     7,     6,   602,  4827,  2819,    15,  2694,  2819,\n",
            "           15,   436,     1],\n",
            "       [    0,  8816,  5073,    23,   229,   219,   645,  9854,    17,\n",
            "         1864,   122,  2211,  6807,   559,  3411,     6,   561,    67,\n",
            "            3, 19594,    29],\n",
            "       [    0, 10194,    35,     3, 11950,    17,     3,  7667,   219,\n",
            "          236,   891,  6184,   510,    67, 15671,   256,  5728,    74,\n",
            "          781,    17, 22033],\n",
            "       [    0, 26606,    77,  8571,  2922,    15,     3,   547,   426,\n",
            "          340,  1546,  3225, 16419,    16, 16504,   236, 18130,     7,\n",
            "           26,   144,   440],\n",
            "       [    0,   660,  2802,    16,    26,  2014,  6552, 17791, 13346,\n",
            "        12524,  5073,    23,     3, 16774,  1110,  2662,  2837,  2014,\n",
            "            7,   736,    17],\n",
            "       [    0,  3080,  1620,  1370,     3,   547,    74,   781,   397,\n",
            "         5380,    17,  7342,   193,  2282,   122, 18711,    35,    16,\n",
            "          445,  2256,    29],\n",
            "       [    0,   316, 16483, 11865,     6,    74, 23566,  4736,  1352,\n",
            "          311,    46, 16090,    64,     3, 21638,  3067,   219,    67,\n",
            "        14343,    15,     7]]), label_ids=array([[  316,   389,   157, ...,  -100,  -100,  -100],\n",
            "       [  316, 16483,   193, ...,  -100,  -100,  -100],\n",
            "       [  848,   551,    36, ...,  -100,  -100,  -100],\n",
            "       ...,\n",
            "       [10194,    35,     7, ...,    35,     5,     1],\n",
            "       [ 3080,  1620,  1370, ...,  -100,  -100,  -100],\n",
            "       [  316, 16483, 20689, ...,  -100,  -100,  -100]]), metrics={'test_loss': 0.9911052584648132, 'test_bleu': 19.48904100922162, 'test_runtime': 1.3194, 'test_samples_per_second': 16.675, 'test_steps_per_second': 2.274})\n"
          ]
        }
      ],
      "source": [
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JW0qoZ9G31L",
        "outputId": "b0096f5a-0df7-44f7-eb57-2f0441c20501"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('t5-en-de-translator/tokenizer_config.json',\n",
              " 't5-en-de-translator/special_tokens_map.json',\n",
              " 't5-en-de-translator/spiece.model',\n",
              " 't5-en-de-translator/added_tokens.json',\n",
              " 't5-en-de-translator/tokenizer.json')"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"t5-en-de-translator\")\n",
        "tokenizer.save_pretrained(\"t5-en-de-translator\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "d4b54c8a61b14bd28eb03d64061ea2e1"
          ]
        },
        "id": "kvD-aFbQG31M",
        "outputId": "a0a566e8-1a1c-4c1c-f7e8-aafde7e5843a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4b54c8a61b14bd28eb03d64061ea2e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "# Login once\n",
        "notebook_login()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "dfbf7063e0224461b34fe143ee048ba0",
            "0c90361f519649059ebaef0cf8e06704",
            "8f2d3cdb1ae941a688f11cbfca3daec5",
            "f6e77257ce3b42fab4fce3696b9897dd",
            "904265cc10984e48bfa1b227d126a08f",
            "055dfb27932849c09e2e56573174994d",
            "218f784296464f0c93c3ba75f2751a21"
          ]
        },
        "id": "9atv_mMZG31N",
        "outputId": "8bef7f0e-7654-48e7-f259-06caf490af29"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfbf7063e0224461b34fe143ee048ba0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c90361f519649059ebaef0cf8e06704",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload                         : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f2d3cdb1ae941a688f11cbfca3daec5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  t5-en-de-translator/model.safetensors :   0%|          |  551kB /  242MB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6e77257ce3b42fab4fce3696b9897dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "904265cc10984e48bfa1b227d126a08f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "055dfb27932849c09e2e56573174994d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload                         : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "218f784296464f0c93c3ba75f2751a21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  t5-en-de-translator/spiece.model      : 100%|##########|  792kB /  792kB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/chinesemusk/t5-en-de-translator/commit/4ddba9a6ed3e684bc4be20b226ef52e3f30efb92', commit_message='Upload tokenizer', commit_description='', oid='4ddba9a6ed3e684bc4be20b226ef52e3f30efb92', pr_url=None, repo_url=RepoUrl('https://huggingface.co/chinesemusk/t5-en-de-translator', endpoint='https://huggingface.co', repo_type='model', repo_id='chinesemusk/t5-en-de-translator'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "repo_id = \"chinesemusk/t5-en-de-translator\"\n",
        "\n",
        "# Push model + tokenizer\n",
        "model.push_to_hub(repo_id)\n",
        "tokenizer.push_to_hub(repo_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "e0b4289584e3401599edf7a9dcee04c1",
            "67d48ffdbd8547939cbc814acd32b116",
            "0e4b0b6f8065448db9a9500fe71dbc5e",
            "1976e9f827794dac92ece71b80e509c7",
            "381a1f33cbea4fc79c70d6a354bc1708",
            "47402cbcd7dc418db387bb8c104c206f",
            "0de9f7627ffd472fb1da5aa1c926e665"
          ]
        },
        "id": "9oPRC3OCG31O",
        "outputId": "72d1a183-0381-4eae-8390-093bd392df73"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0b4289584e3401599edf7a9dcee04c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67d48ffdbd8547939cbc814acd32b116",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e4b0b6f8065448db9a9500fe71dbc5e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1976e9f827794dac92ece71b80e509c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "381a1f33cbea4fc79c70d6a354bc1708",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47402cbcd7dc418db387bb8c104c206f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0de9f7627ffd472fb1da5aa1c926e665",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Das ist ein Test.\n"
          ]
        }
      ],
      "source": [
        "# use the model from HF\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"chinesemusk/t5-en-de-translator\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"chinesemusk/t5-en-de-translator\")\n",
        "\n",
        "text = \"Das ist ein Test.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g89GKeYgG31P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-sPHSAbG31j"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}